{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e211547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyglot_data] Downloading package embeddings2.en to\n",
      "[polyglot_data]     /home/ubuntu/polyglot_data...\n",
      "[polyglot_data]   Package embeddings2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package embeddings2.hi to\n",
      "[polyglot_data]     /home/ubuntu/polyglot_data...\n",
      "[polyglot_data]   Package embeddings2.hi is already up-to-date!\n",
      "[polyglot_data] Downloading package embeddings2.ta to\n",
      "[polyglot_data]     /home/ubuntu/polyglot_data...\n",
      "[polyglot_data]   Package embeddings2.ta is already up-to-date!\n",
      "[polyglot_data] Downloading package transliteration2.hi to\n",
      "[polyglot_data]     /home/ubuntu/polyglot_data...\n",
      "[polyglot_data]   Package transliteration2.hi is already up-to-date!\n",
      "[polyglot_data] Downloading package transliteration2.ta to\n",
      "[polyglot_data]     /home/ubuntu/polyglot_data...\n",
      "[polyglot_data]   Package transliteration2.ta is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from polyglot.downloader import downloader\n",
    "downloader.download(\"embeddings2.en\")\n",
    "downloader.download(\"embeddings2.hi\")\n",
    "downloader.download(\"embeddings2.ta\")\n",
    "downloader.download(\"transliteration2.hi\")\n",
    "downloader.download(\"transliteration2.ta\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from progressbar import progressbar\n",
    "from datasets import load_metric\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b54a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where you untar the downloaded file\n",
    "data_folder = \"/home/ubuntu/speech_data/t-seed/MSR/microsoftspeechcorpusindianlanguages/ta-in-Test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b17188",
   "metadata": {},
   "outputs": [],
   "source": [
    "variation = \"Transliterated\"\n",
    "e_type=\"base\"\n",
    "noise_variation = \"laughter\" # none, rain, wind, laughter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49eee123",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_file = os.path.join(data_folder, \"transcription.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95a86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(tsv_file, sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "024453c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3081, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9379dfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>440203</td>\n",
       "      <td>நேபாளத்தில் ஏற்பட்ட நிலநடுக்கத்தில் பாதிக்கப்ப...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>520021</td>\n",
       "      <td>நீங்க அழகா இருக்கீங்க என்று சொல்வது அப்போதைக்க...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150447</td>\n",
       "      <td>சம்பந்தப்பட்ட கடல் பகுதிகளில் உள்ள மாநில அரசிட...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                                  1\n",
       "0  440203  நேபாளத்தில் ஏற்பட்ட நிலநடுக்கத்தில் பாதிக்கப்ப...\n",
       "1  520021  நீங்க அழகா இருக்கீங்க என்று சொல்வது அப்போதைக்க...\n",
       "2  150447  சம்பந்தப்பட்ட கடல் பகுதிகளில் உள்ள மாநில அரசிட..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48802cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add full path to the file names in the column data_frame[\"audios\"]\n",
    "import re\n",
    "import polyglot\n",
    "from polyglot.text import Text\n",
    "\n",
    "\n",
    "new_list = list()\n",
    "for item in list(data_frame[0]):\n",
    "    i_len = len(str(item))\n",
    "    k = 9 - i_len\n",
    "    item_str = \"\".join(([\"0\"] * k) + [str(item)])\n",
    "    new_list.append(item_str + \".wav\")\n",
    "    \n",
    "    \n",
    "\n",
    "def get_transliterations(t):\n",
    "    t = Text(t, hint_language_code=\"ta\")\n",
    "    t = (\" \".join(list(t.transliterate(\"en\"))))\n",
    "    return t\n",
    "\n",
    "# lower case the transcripts in the column data_frame[\"text\"]\n",
    "\n",
    "data_frame[\"text\"] = data_frame[1].apply(lambda x: get_transliterations(x))\n",
    "\n",
    "# removing special characters from the transcripts in the column data_frame[\"text\"]\n",
    "\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�]'\n",
    "\n",
    "def remove_special_characters(sentence):\n",
    "    sentence = re.sub(chars_to_ignore_regex, '', sentence)\n",
    "    return sentence\n",
    "\n",
    "data_frame[\"text\"] = data_frame[\"text\"].apply(lambda x: remove_special_characters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c72fc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>440203</td>\n",
       "      <td>நேபாளத்தில் ஏற்பட்ட நிலநடுக்கத்தில் பாதிக்கப்ப...</td>\n",
       "      <td>nebalthil atpat nilndukthil badikpptt mkluku a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>520021</td>\n",
       "      <td>நீங்க அழகா இருக்கீங்க என்று சொல்வது அப்போதைக்க...</td>\n",
       "      <td>neenga azhka irukkeinga enru solvdu appothikek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150447</td>\n",
       "      <td>சம்பந்தப்பட்ட கடல் பகுதிகளில் உள்ள மாநில அரசிட...</td>\n",
       "      <td>smbandpptt kdl bucudiklil ull manil arsidam id...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                                  1  \\\n",
       "0  440203  நேபாளத்தில் ஏற்பட்ட நிலநடுக்கத்தில் பாதிக்கப்ப...   \n",
       "1  520021  நீங்க அழகா இருக்கீங்க என்று சொல்வது அப்போதைக்க...   \n",
       "2  150447  சம்பந்தப்பட்ட கடல் பகுதிகளில் உள்ள மாநில அரசிட...   \n",
       "\n",
       "                                                text  \n",
       "0  nebalthil atpat nilndukthil badikpptt mkluku a...  \n",
       "1  neenga azhka irukkeinga enru solvdu appothikek...  \n",
       "2  smbandpptt kdl bucudiklil ull manil arsidam id...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c6e31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame[\"audios\"] = new_list\n",
    "data_frame[\"audios\"] = data_frame[\"audios\"].apply(lambda x: os.path.join(data_folder, \"Audios\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f4aea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/speech_data/t-seed/MSR/microsoftspeechcorpusindianlanguages/ta-in-Test/Audios/000520021.wav\n"
     ]
    }
   ],
   "source": [
    "# viewing path of a single file\n",
    "# \"/home/ubuntu/speech_data/t-seed/LibriSpeech/\" will be path where you untar the downloaded file\n",
    "print(data_frame[\"audios\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "720f5618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050\n"
     ]
    }
   ],
   "source": [
    "# check one file from the data_frame for specifications\n",
    "audio_array, sampling_rate = librosa.load(data_frame[\"audios\"][1])\n",
    "\n",
    "print(sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2c9c926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.0006323 , -0.00071442, -0.00069315, ...,  0.00147659,\n",
       "         0.00207009,  0.00138447], dtype=float32),\n",
       " 22050)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.load(data_frame[\"audios\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f40de287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "# resampling audio file to 16 KHz\n",
    "\n",
    "audio_array, sampling_rate = librosa.load(data_frame[\"audios\"][1], sr=16000)\n",
    "print(sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69a218b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11896\n"
     ]
    }
   ],
   "source": [
    "# getting unique words in the transcripts to use it with the language modeler\n",
    "\n",
    "words = \" \".join(list(data_frame[\"text\"])).split()\n",
    "unique_words = list(set(words))\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23ff0d",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c060ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import config\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "transcriber_processor = Wav2Vec2Processor.from_pretrained(\"wav2vec2-large-rbg-tamil\")\n",
    "transcriber_processor.tokenizer.do_lower_case = True\n",
    "transcriber_encoder_model = Wav2Vec2ForCTC.from_pretrained(\"wav2vec2-large-rbg-tamil\")\n",
    "\n",
    "transcriber_encoder_model  = transcriber_encoder_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f08a35f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise folder path\n",
    "noise_folder = \"noise/matrix/\"\n",
    "\n",
    "rain_noises = ['1-56311-A-10.wav', '1-63871-A-10.wav', '2-101676-A-10.wav', '2-117625-A-10.wav', '5-181766-A-10.wav', '5-188655-A-10.wav', '3-157487-A-10.wav', '3-157615-A-10.wav', '4-160999-A-10.wav', '4-161127-A-10.wav']\n",
    "wind_noises = ['1-51037-A-16.wav', '1-69760-A-16.wav', '2-104952-A-16.wav', '2-104952-B-16.wav', '3-246513-A-16.wav', '3-246513-B-16.wav', '4-144083-A-16.wav', '4-144083-B-16.wav', '5-157204-A-16.wav', '5-157204-B-16.wav']\n",
    "laughter_noises = ['1-72695-A-26.wav', '1-73123-A-26.wav', '2-109759-A-26.wav','2-109759-B-26.wav', '3-152912-A-26.wav', '3-152997-A-26.wav', '4-132803-A-26.wav', '4-132810-A-26.wav', '5-242932-B-26.wav','5-244526-A-26.wav']\n",
    "\n",
    "rain_noises = [os.path.join(noise_folder, file) for file in rain_noises]\n",
    "wind_noises = [os.path.join(noise_folder, file) for file in wind_noises]\n",
    "laughter_noises = [os.path.join(noise_folder, file) for file in laughter_noises]\n",
    "\n",
    "noise_dict = {'rain': rain_noises, 'wind': wind_noises, 'laughter': laughter_noises}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cedfb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction against base model with and without language modeler\n",
    "\n",
    "def get_transcriptions(audio_path, unique_words, e_type=\"base\", noise_type=\"none\"):\n",
    "    \n",
    "    if noise_type == \"none\":\n",
    "        audio_array, sampling_rate = librosa.load(audio_path, sr=16000)\n",
    "    else:\n",
    "        GAIN_CONSTANT = -34.\n",
    "        NOISE_VOLUME=0.3\n",
    "        noise_file = random.choice(noise_dict[noise_type])\n",
    "        audio = AudioSegment.from_file(audio_path, 'wav')\n",
    "        audio = audio.normalize()\n",
    "        background = AudioSegment.from_file(noise_file, 'wav')\n",
    "        background = background.normalize()\n",
    "        background = background.apply_gain(GAIN_CONSTANT * (1. - 0.3))\n",
    "        output = audio.overlay(background, position=0, loop=True)\n",
    "        output = output.set_frame_rate(16000)\n",
    "        output.export(\"temp.wav\", format='wav')\n",
    "        audio_array, sampling_rate = librosa.load(\"temp.wav\", sr=16000)\n",
    "        \n",
    "    inputs = transcriber_processor(audio_array, sampling_rate=16000,\n",
    "                                       return_tensors=\"pt\", padding=True)\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "            character_probability = transcriber_encoder_model(inputs.input_values,\n",
    "                                                              attention_mask=inputs.attention_mask).logits\n",
    "    inputs = inputs.to(\"cpu\")\n",
    "    predicted_ids = torch.argmax(character_probability, dim=-1)\n",
    "    encoder_text = transcriber_processor.batch_decode(predicted_ids)[0]\n",
    "    \n",
    "    decoder_text = \"None\" # \"not disclosed\"\n",
    "    \n",
    "    return encoder_text, decoder_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99cde909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 3081) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--/home/ubuntu/AISS/common/transformers/feature_extraction_utils.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = as_tensor(value)\n",
      "/home/ubuntu/AISS/common/transformers/models/wav2vec2/modeling_wav2vec2.py:875: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      "100% (3081 of 3081) |####################| Elapsed Time: 0:35:58 Time:  0:35:58\n"
     ]
    }
   ],
   "source": [
    "without_lm_op = list()\n",
    "with_lm_op = list()\n",
    "\n",
    "for item in progressbar(data_frame[\"audios\"]):\n",
    "    e_text, d_text = get_transcriptions(item, unique_words, e_type=\"base\", noise_type=noise_variation)\n",
    "    without_lm_op.append(e_text)\n",
    "    with_lm_op.append(d_text)\n",
    "\n",
    "data_frame[\"without_lm\"] = without_lm_op\n",
    "data_frame[\"with_lm\"] = with_lm_op\n",
    "data_frame.to_csv(\"results/MSR-Tamil-\"+ e_type  + \"-\" + variation + \"-\" + noise_variation + \".tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c8242e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>text</th>\n",
       "      <th>audios</th>\n",
       "      <th>without_lm</th>\n",
       "      <th>with_lm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>440203</td>\n",
       "      <td>நேபாளத்தில் ஏற்பட்ட நிலநடுக்கத்தில் பாதிக்கப்ப...</td>\n",
       "      <td>nebalthil atpat nilndukthil badikpptt mkluku a...</td>\n",
       "      <td>/home/ubuntu/speech_data/t-seed/MSR/microsofts...</td>\n",
       "      <td>nabalthil iarptt nilenrukthil badikpptt mkluku...</td>\n",
       "      <td>nebalthil arpptt nilndukthil badikpptt mkluku ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>520021</td>\n",
       "      <td>நீங்க அழகா இருக்கீங்க என்று சொல்வது அப்போதைக்க...</td>\n",
       "      <td>neenga azhka irukkeinga enru solvdu appothikek...</td>\n",
       "      <td>/home/ubuntu/speech_data/t-seed/MSR/microsofts...</td>\n",
       "      <td>neenga azhka irukkeinga  enru solvdu  appothik...</td>\n",
       "      <td>neenga azhka irukkeinga  enru solvdu  appothik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150447</td>\n",
       "      <td>சம்பந்தப்பட்ட கடல் பகுதிகளில் உள்ள மாநில அரசிட...</td>\n",
       "      <td>smbandpptt kdl bucudiklil ull manil arsidam id...</td>\n",
       "      <td>/home/ubuntu/speech_data/t-seed/MSR/microsofts...</td>\n",
       "      <td>samandpt kdlbucurealil ull manil arsidam iduku...</td>\n",
       "      <td>sarand kdl bucudeail ull manil arsidam idu kur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80140</td>\n",
       "      <td>தமிழ்நாட்டு திரைப்பட இயக்குனர்கள் சங்கம் இன்று...</td>\n",
       "      <td>dmizhnnattu diraippd iykunerkl sngam inru ndat...</td>\n",
       "      <td>/home/ubuntu/speech_data/t-seed/MSR/microsofts...</td>\n",
       "      <td>dmizhnattud diraippd akunerkl sngam enru ndath...</td>\n",
       "      <td>dmizhnnattu diraippd aku neril sngam enru ndat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1300218</td>\n",
       "      <td>பாகிஸ்தானில் பிறந்ததை தவிர அந்த பிஞ்சுகள் செய்...</td>\n",
       "      <td>bakistanil branddai dvir anth binjukl said bav...</td>\n",
       "      <td>/home/ubuntu/speech_data/t-seed/MSR/microsofts...</td>\n",
       "      <td>bakitnil branddaid dvir anthb binjukl said bav...</td>\n",
       "      <td>bakistanil branddai dvir anthb binjukl said ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1  \\\n",
       "0   440203  நேபாளத்தில் ஏற்பட்ட நிலநடுக்கத்தில் பாதிக்கப்ப...   \n",
       "1   520021  நீங்க அழகா இருக்கீங்க என்று சொல்வது அப்போதைக்க...   \n",
       "2   150447  சம்பந்தப்பட்ட கடல் பகுதிகளில் உள்ள மாநில அரசிட...   \n",
       "3    80140  தமிழ்நாட்டு திரைப்பட இயக்குனர்கள் சங்கம் இன்று...   \n",
       "4  1300218  பாகிஸ்தானில் பிறந்ததை தவிர அந்த பிஞ்சுகள் செய்...   \n",
       "\n",
       "                                                text  \\\n",
       "0  nebalthil atpat nilndukthil badikpptt mkluku a...   \n",
       "1  neenga azhka irukkeinga enru solvdu appothikek...   \n",
       "2  smbandpptt kdl bucudiklil ull manil arsidam id...   \n",
       "3  dmizhnnattu diraippd iykunerkl sngam inru ndat...   \n",
       "4  bakistanil branddai dvir anth binjukl said bav...   \n",
       "\n",
       "                                              audios  \\\n",
       "0  /home/ubuntu/speech_data/t-seed/MSR/microsofts...   \n",
       "1  /home/ubuntu/speech_data/t-seed/MSR/microsofts...   \n",
       "2  /home/ubuntu/speech_data/t-seed/MSR/microsofts...   \n",
       "3  /home/ubuntu/speech_data/t-seed/MSR/microsofts...   \n",
       "4  /home/ubuntu/speech_data/t-seed/MSR/microsofts...   \n",
       "\n",
       "                                          without_lm  \\\n",
       "0  nabalthil iarptt nilenrukthil badikpptt mkluku...   \n",
       "1  neenga azhka irukkeinga  enru solvdu  appothik...   \n",
       "2  samandpt kdlbucurealil ull manil arsidam iduku...   \n",
       "3  dmizhnattud diraippd akunerkl sngam enru ndath...   \n",
       "4  bakitnil branddaid dvir anthb binjukl said bav...   \n",
       "\n",
       "                                             with_lm  \n",
       "0  nebalthil arpptt nilndukthil badikpptt mkluku ...  \n",
       "1  neenga azhka irukkeinga  enru solvdu  appothik...  \n",
       "2  sarand kdl bucudeail ull manil arsidam idu kur...  \n",
       "3  dmizhnnattu diraippd aku neril sngam enru ndat...  \n",
       "4  bakistanil branddai dvir anthb binjukl said ba...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6cae54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load_metric(\"wer\")\n",
    "without_lm_wer = wer_metric.compute(predictions=data_frame[\"without_lm\"], references=data_frame[\"text\"])\n",
    "with_lm_wer = wer_metric.compute(predictions=data_frame[\"with_lm\"], references=data_frame[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc524b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7450738916256158"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_lm_wer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f520993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.434900109469075"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_lm_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37817a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiss",
   "language": "python",
   "name": "aiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
