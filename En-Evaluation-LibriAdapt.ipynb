{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e211547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from progressbar import progressbar\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b54a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where you untar the downloaded file (~path~of~/t-seed/LibriSpeech/)\n",
    "data_folder = \"/home/ubuntu/speech_data/t-seed/LibriAdapt/en-us\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72fab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "variation1 = \"rain\" # possbile values (clean, rain, wind, laughter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b17188",
   "metadata": {},
   "outputs": [],
   "source": [
    "variation2 = \"matrix\" # possbile values (matrix, nexus6, pseye, respeaker, shure, usb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49eee123",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_file = os.path.join(data_folder,  variation2 + \".tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c95a86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(tsv_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "024453c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9379dfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>audios</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8555-292519-0000.wav</td>\n",
       "      <td>brighter than early dawn's most brilliant dye ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8555-292519-0001.wav</td>\n",
       "      <td>guided by you how we might stroll towards deat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8555-292519-0002.wav</td>\n",
       "      <td>venice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                audios  \\\n",
       "0           0  8555-292519-0000.wav   \n",
       "1           1  8555-292519-0001.wav   \n",
       "2           2  8555-292519-0002.wav   \n",
       "\n",
       "                                                text  \n",
       "0  brighter than early dawn's most brilliant dye ...  \n",
       "1  guided by you how we might stroll towards deat...  \n",
       "2                                             venice  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48802cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add full path to the file names in the column data_frame[\"audios\"]\n",
    "\n",
    "data_frame[\"audios\"] = data_frame[\"audios\"].apply(lambda x: os.path.join(\n",
    "    data_folder, variation1, variation2, \"test\", x))\n",
    "\n",
    "\n",
    "# lower case the transcripts in the column data_frame[\"text\"]\n",
    "\n",
    "data_frame[\"text\"] = data_frame[\"text\"].apply(lambda x: x.lower())\n",
    "\n",
    "# removing special characters from the transcripts in the column data_frame[\"text\"]\n",
    "\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�]'\n",
    "\n",
    "def remove_special_characters(sentence):\n",
    "    sentence = re.sub(chars_to_ignore_regex, '', sentence)\n",
    "    return sentence\n",
    "\n",
    "data_frame[\"text\"] = data_frame[\"text\"].apply(lambda x: remove_special_characters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c72fc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>audios</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/home/ubuntu/speech_data/t-seed/LibriAdapt/en-...</td>\n",
       "      <td>brighter than early dawn's most brilliant dye ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/ubuntu/speech_data/t-seed/LibriAdapt/en-...</td>\n",
       "      <td>guided by you how we might stroll towards deat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/home/ubuntu/speech_data/t-seed/LibriAdapt/en-...</td>\n",
       "      <td>venice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             audios  \\\n",
       "0           0  /home/ubuntu/speech_data/t-seed/LibriAdapt/en-...   \n",
       "1           1  /home/ubuntu/speech_data/t-seed/LibriAdapt/en-...   \n",
       "2           2  /home/ubuntu/speech_data/t-seed/LibriAdapt/en-...   \n",
       "\n",
       "                                                text  \n",
       "0  brighter than early dawn's most brilliant dye ...  \n",
       "1  guided by you how we might stroll towards deat...  \n",
       "2                                             venice  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f4aea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/speech_data/t-seed/LibriAdapt/en-us/rain/matrix/test/8555-292519-0001.wav\n"
     ]
    }
   ],
   "source": [
    "# viewing path of a single file\n",
    "# \"/home/ubuntu/speech_data/t-seed/LibriSpeech/\" will be path where you untar the downloaded file\n",
    "print(data_frame[\"audios\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "720f5618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050\n"
     ]
    }
   ],
   "source": [
    "# check one file from the data_frame for specifications\n",
    "audio_array, sampling_rate = librosa.load(data_frame[\"audios\"][1])\n",
    "\n",
    "print(sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f40de287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "# resampling audio file to 16 KHz\n",
    "\n",
    "audio_array, sampling_rate = librosa.load(data_frame[\"audios\"][1], sr=16000)\n",
    "print(sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69a218b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7991\n"
     ]
    }
   ],
   "source": [
    "# getting unique words in the transcripts to use it with the language modeler\n",
    "\n",
    "words = \" \".join(list(data_frame[\"text\"])).split()\n",
    "unique_words = list(set(words))\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23ff0d",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c060ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import config\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "transcriber_processor = Wav2Vec2Processor.from_pretrained(\"wav2vec2-large-rbg-tamil/\")\n",
    "transcriber_processor.tokenizer.do_lower_case = True\n",
    "transcriber_encoder_model = Wav2Vec2ForCTC.from_pretrained(\"wav2vec2-large-rbg-tamil/\")\n",
    "\n",
    "transcriber_encoder_model  = transcriber_encoder_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cedfb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction against base model with and without language modeler\n",
    "\n",
    "def get_transcriptions(audio_path, unique_words, e_type=\"base_model\"):\n",
    "    \n",
    "    \n",
    "    encoder_text, decoder_text = \"None\", \"None\" # \"Not disclosed\"\n",
    "    \n",
    "    return encoder_text, decoder_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cde909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 2600) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--/home/ubuntu/AISS/common/transformers/feature_extraction_utils.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = as_tensor(value)\n",
      "/home/ubuntu/AISS/common/transformers/models/wav2vec2/modeling_wav2vec2.py:875: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      " 31% (829 of 2600) |######               | Elapsed Time: 0:20:14 ETA:   0:37:19"
     ]
    }
   ],
   "source": [
    "without_lm_op = list()\n",
    "with_lm_op = list()\n",
    "e_type = \"enhanced\"\n",
    "for item in progressbar(data_frame[\"audios\"]):\n",
    "    e_text, d_text = get_transcriptions(item, unique_words, e_type=e_type)\n",
    "    without_lm_op.append(e_text)\n",
    "    with_lm_op.append(d_text)\n",
    "\n",
    "data_frame[\"without_lm\"] = without_lm_op\n",
    "data_frame[\"with_lm\"] = with_lm_op\n",
    "data_frame.to_csv(\"results/LibriAdapt-\"+ variation1 +\"-\"+ variation2 + \"-\" + e_type + \".tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8242e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cae54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load_metric(\"wer\")\n",
    "without_lm_wer = wer_metric.compute(predictions=data_frame[\"without_lm\"], references=data_frame[\"text\"])\n",
    "with_lm_wer = wer_metric.compute(predictions=data_frame[\"with_lm\"], references=data_frame[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc524b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09664169616836506"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_lm_wer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f520993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06065288399475815"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_lm_wer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiss",
   "language": "python",
   "name": "aiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
